# ç¦»çº¿ä»¿çœŸè„šæœ¬ï¼šåŠ è½½Checkpointå¤ç°OCCTç¯å¢ƒç­–ç•¥
# å®Œå…¨é€‚é…TwoCarrierEnvæºç ç‰ˆï¼šç²¾å‡†åŒ¹é…ç¯å¢ƒåˆå§‹åŒ–/äº¤äº’/å¯è§†åŒ–é€»è¾‘
from __future__ import annotations
import sys
import os
import warnings
import pickle
import numpy as np
import torch
import argparse
import omegaconf
from omegaconf import DictConfig, OmegaConf

# ===================== é¢„å¤„ç†ï¼šå±è”½æ— å…³è­¦å‘Š + ç¯å¢ƒé…ç½® =====================
# 1. å…è®¸OmegaConf.DictConfigè¢«ååºåˆ—åŒ–
torch.serialization.add_safe_globals([DictConfig, omegaconf.dictconfig.DictConfig])
# 2. å±è”½æ‰€æœ‰æ— å…³è­¦å‘Š
warnings.filterwarnings("ignore")
# 3. æ£€æŸ¥CUDAç¯å¢ƒ
CUDA_AVAILABLE = torch.cuda.is_available()
print(f"ğŸ” CUDA available: {CUDA_AVAILABLE}")
if not CUDA_AVAILABLE:
    print(f"   â†’ å¼ºåˆ¶ä½¿ç”¨CPUåŠ è½½Checkpointå’Œè¿è¡Œä»¿çœŸ")

# ===================== æ ¸å¿ƒï¼šæ·»åŠ ä½ çš„ä»£ç æ ¹ç›®å½• =====================
sys.path.insert(0, "E:\\rl")  

# ===================== å¯¼å…¥å¿…éœ€æ¨¡å—ï¼ˆåŸºäºTwoCarrierEnvæºç ï¼‰ =====================
from utils_ppo_occt import make_ppo_models  # ä»…å¯¼å…¥æ¨¡å‹åˆ›å»º
from occt_2d2c import TwoCarrierEnv  # ç›´æ¥å¯¼å…¥åŸå§‹ç¯å¢ƒ

# ===================== å·¥å…·å‡½æ•°ï¼šåˆ›å»ºåŸå§‹TwoCarrierEnvç¯å¢ƒï¼ˆç²¾å‡†åŒ¹é…æºç ï¼‰ =====================
def create_raw_env(cfg, render_mode, config_path, enable_visualization, vecnorm_frozen):
    """
    ç²¾å‡†åˆ›å»ºTwoCarrierEnvç¯å¢ƒï¼ˆå®Œå…¨åŒ¹é…æºç åˆå§‹åŒ–å‚æ•°ï¼‰
    :param cfg: é…ç½®å­—å…¸/å¯¹è±¡
    :param render_mode: æ¸²æŸ“æ¨¡å¼ "human"/"rgb_array"/None
    :param config_path: 2d2c.yamlé…ç½®æ–‡ä»¶è·¯å¾„
    :param enable_visualization: æ˜¯å¦å¯ç”¨å¯è§†åŒ–
    :param vecnorm_frozen: æ˜¯å¦å†»ç»“VecNormç»Ÿè®¡é‡
    :return: TwoCarrierEnvå®ä¾‹
    """
    # ä»cfgä¸­æå–config_pathï¼ˆä¼˜å…ˆä½¿ç”¨cfgä¸­çš„é…ç½®ï¼‰
    env_config_path = None
    if hasattr(cfg, 'env') and hasattr(cfg.env, 'config_path'):
        env_config_path = cfg.env.config_path
    
    # ä¼˜å…ˆçº§ï¼šæ˜¾å¼ä¼ å…¥çš„config_path > cfgä¸­çš„config_path > Noneï¼ˆä½¿ç”¨é»˜è®¤ï¼‰
    final_config_path = config_path if config_path is not None else env_config_path
    
    # ç²¾å‡†åˆå§‹åŒ–TwoCarrierEnvï¼ˆå®Œå…¨åŒ¹é…æºç å‚æ•°ï¼‰
    env = TwoCarrierEnv(
        render_mode=render_mode,
        config_path=final_config_path,
        enable_visualization=enable_visualization,
        vecnorm_frozen=vecnorm_frozen
    )
    return env

# ===================== å·¥å…·å‡½æ•°ï¼šæå–æ¨¡å‹è¾“å‡ºçš„åŠ¨ä½œå¼ é‡ï¼ˆé€‚é…4ç»´åŠ¨ä½œç©ºé—´ï¼‰ =====================
def extract_action_from_model_output(model_output, device):
    """
    ä»æ¨¡å‹è¾“å‡ºä¸­æå–4ç»´åŠ¨ä½œå¼ é‡ï¼Œå¹¶ç¡®ä¿å½’ä¸€åŒ–åˆ°[-1,1]åŒºé—´
    :param model_output: æ¨¡å‹è¾“å‡ºï¼ˆå¼ é‡/å…ƒç»„ï¼‰
    :param device: è¿è¡Œè®¾å¤‡
    :return: 4ç»´åŠ¨ä½œå¼ é‡ï¼ˆå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
    """
    # æå–åŠ¨ä½œå¼ é‡
    if isinstance(model_output, torch.Tensor):
        action_tensor = model_output
    elif isinstance(model_output, tuple):
        action_tensor = model_output[0]  # PPOæ¨¡å‹å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆåŠ¨ä½œï¼‰
    else:
        action_tensor = torch.tensor(model_output, device=device)
    
    # ç¡®ä¿æ˜¯4ç»´åŠ¨ä½œï¼ˆåŒ¹é…ç¯å¢ƒçš„åŠ¨ä½œç©ºé—´ï¼‰
    if action_tensor.shape[-1] != 4:
        raise ValueError(f"æ¨¡å‹è¾“å‡ºåŠ¨ä½œç»´åº¦é”™è¯¯ï¼ŒæœŸæœ›4ç»´ï¼Œå®é™…{action_tensor.shape[-1]}ç»´")
    
    # è£å‰ªåˆ°[-1,1]ï¼ˆç¡®ä¿ç¬¦åˆç¯å¢ƒçš„å½’ä¸€åŒ–åŠ¨ä½œç©ºé—´è¦æ±‚ï¼‰
    action_tensor = torch.clamp(action_tensor, -1.0, 1.0)
    
    return action_tensor

# ===================== å‘½ä»¤è¡Œå‚æ•°é…ç½®ï¼ˆé€‚é…ç¯å¢ƒç‰¹æ€§ï¼‰ =====================
def parse_args():
    parser = argparse.ArgumentParser(description="Offline Simulation for OCCT TwoCarrierEnv Policy")
    parser.add_argument("--ckpt_path", type=str, required=True, help="Checkpointæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--num_episodes", type=int, default=5, help="ä»¿çœŸè½®æ•°")
    parser.add_argument("--device", type=str, default="cuda:0" if CUDA_AVAILABLE else "cpu", help="è¿è¡Œè®¾å¤‡")
    parser.add_argument("--enable_visualization", action="store_true", help="å¯ç”¨å¯è§†åŒ–")
    parser.add_argument("--render_mode", type=str, default="rgb_array", choices=["human", "rgb_array"], 
                        help="æ¸²æŸ“æ¨¡å¼ï¼šhuman(å®æ—¶æ˜¾ç¤º)/rgb_array(ä¿å­˜è§†é¢‘)")
    parser.add_argument("--save_video", action="store_true", help="ä¿å­˜è§†é¢‘ï¼ˆéœ€å¯ç”¨å¯è§†åŒ–+rgb_arrayæ¨¡å¼ï¼‰")
    parser.add_argument("--video_dir", type=str, default="", help="è§†é¢‘ä¿å­˜ç›®å½•")
    parser.add_argument("--config_path", type=str, default=None, help="2d2c.yamlé…ç½®æ–‡ä»¶è·¯å¾„")
    return parser.parse_args()

# ===================== æ ¸å¿ƒå‡½æ•°ï¼šåŠ è½½Checkpointï¼ˆåŒ…å«VecNormçŠ¶æ€ï¼‰ =====================
def load_checkpoint(ckpt_path, device):
    """
    åŠ è½½Checkpointï¼ŒåŒ…å«æ¨¡å‹æƒé‡å’ŒVecNormçŠ¶æ€
    :param ckpt_path: Checkpointè·¯å¾„
    :param device: è¿è¡Œè®¾å¤‡
    :return: actoræ¨¡å‹, cfgé…ç½®, vecnorm_stateå½’ä¸€åŒ–çŠ¶æ€
    """
    if not os.path.exists(ckpt_path):
        raise FileNotFoundError(f"Checkpointä¸å­˜åœ¨: {ckpt_path}")
    
    map_location = torch.device(device) if CUDA_AVAILABLE else torch.device("cpu")
    print(f"ğŸ“¥ åŠ è½½Checkpointåˆ°è®¾å¤‡: {map_location}")
    
    # åŠ è½½Checkpointï¼ˆå…¼å®¹PyTorch 2.6+ï¼‰
    try:
        ckpt_dict = torch.load(
            ckpt_path, 
            map_location=map_location,
            weights_only=False,
            pickle_module=pickle
        )
    except Exception as e:
        print(f"âš ï¸ åˆå§‹åŠ è½½å¤±è´¥ï¼Œå°è¯•é™çº§æ–¹æ¡ˆï¼š{e}")
        with torch.serialization.safe_globals([DictConfig]):
            ckpt_dict = torch.load(ckpt_path, map_location=map_location, weights_only=False)
    
    # æ¢å¤æ¨¡å‹
    cfg = ckpt_dict["cfg"]
    actor, _ = make_ppo_models(cfg.env.env_name, device=map_location)
    actor.load_state_dict(ckpt_dict["actor_state_dict"])
    actor.eval()
    
    # æå–VecNormçŠ¶æ€ï¼ˆå…¼å®¹ä¸åŒçš„å­˜å‚¨æ–¹å¼ï¼‰
    vecnorm_state = ckpt_dict.get("vecnorm_state", {
        "vecnorm_mean": ckpt_dict.get("vecnorm_mean", np.zeros(12, dtype=np.float64)),
        "vecnorm_var": ckpt_dict.get("vecnorm_var", np.ones(12, dtype=np.float64) * 1e-4),
        "vecnorm_count": ckpt_dict.get("vecnorm_count", 0),
        "vecnorm_decay": ckpt_dict.get("vecnorm_decay", 0.99999),
        "vecnorm_eps": ckpt_dict.get("vecnorm_eps", 1e-2),
        "vecnorm_frozen": ckpt_dict.get("vecnorm_frozen", True)
    })
    
    print(f"âœ… CheckpointåŠ è½½æˆåŠŸ!")
    print(f"  - è®­ç»ƒå¸§æ•°: {ckpt_dict.get('collected_frames', 'unknown')}")
    print(f"  - VecNormå‡å€¼ï¼ˆå‰5ç»´ï¼‰: {vecnorm_state['vecnorm_mean'][:5].round(6)}")
    print(f"  - VecNormæ¨¡å¼: {'è¯„æµ‹æ¨¡å¼ï¼ˆå†»ç»“ï¼‰' if vecnorm_state['vecnorm_frozen'] else 'è®­ç»ƒæ¨¡å¼ï¼ˆè§£å†»ï¼‰'}")
    
    return actor, cfg, vecnorm_state

# ===================== æ ¸å¿ƒå‡½æ•°ï¼šè¿è¡Œç¦»çº¿ä»¿çœŸï¼ˆå®Œå…¨é€‚é…TwoCarrierEnvï¼‰ =====================
def run_offline_simulation(actor, cfg, vecnorm_state, args):
    final_device = torch.device(args.device) if CUDA_AVAILABLE else torch.device("cpu")
    print(f"\nğŸš€ å¼€å§‹ç¦»çº¿ä»¿çœŸï¼ˆTwoCarrierEnvï¼‰")
    print(f"  è¿è¡Œè®¾å¤‡: {final_device}")
    print(f"  ä»¿çœŸè½®æ•°: {args.num_episodes}")
    print(f"  å¯è§†åŒ–: {'å¯ç”¨' if args.enable_visualization else 'ç¦ç”¨'}")
    print(f"  æ¸²æŸ“æ¨¡å¼: {args.render_mode if args.enable_visualization else 'None'}")
    print(f"  è§†é¢‘ä¿å­˜: {'å¯ç”¨' if (args.save_video and args.enable_visualization and args.render_mode == 'rgb_array') else 'ç¦ç”¨'}")
    
    # 1. åˆ›å»ºåŸå§‹ç¯å¢ƒï¼ˆç²¾å‡†åŒ¹é…TwoCarrierEnvåˆå§‹åŒ–å‚æ•°ï¼‰
    sim_env = create_raw_env(
        cfg=cfg,
        render_mode=args.render_mode if args.enable_visualization else None,
        config_path=args.config_path,
        enable_visualization=args.enable_visualization,
        vecnorm_frozen=vecnorm_state["vecnorm_frozen"]
    )
    print(f"âœ… åˆ›å»ºåŸå§‹ç¯å¢ƒæˆåŠŸ: {type(sim_env)}")
    
    # 2. åŠ è½½å¹¶è®¾ç½®VecNormçŠ¶æ€ï¼ˆå®Œå…¨åŒ¹é…ç¯å¢ƒçš„set_vecnorm_stateæ–¹æ³•ï¼‰
    try:
        sim_env.set_vecnorm_state(vecnorm_state)
        sim_env.freeze_vecnorm()  # å¼ºåˆ¶å†»ç»“ï¼ˆè¯„æµ‹æ¨¡å¼ï¼‰
        print(f"âœ… VecNormçŠ¶æ€åŠ è½½å¹¶å†»ç»“å®Œæˆ")
    except Exception as e:
        print(f"âš ï¸ VecNormçŠ¶æ€åŠ è½½å¤±è´¥: {e}")
    
    # 3. è§†é¢‘ä¿å­˜é…ç½®
    video_save_dir = None
    if args.save_video and args.enable_visualization and args.render_mode == "rgb_array":
        video_save_dir = args.video_dir if args.video_dir else os.path.dirname(args.ckpt_path)
        os.makedirs(video_save_dir, exist_ok=True)
        print(f"âœ… è§†é¢‘ä¿å­˜ç›®å½•: {video_save_dir}")
        sim_env.clear_render_frames()  # æ¸…ç©ºå¸§ç¼“å­˜
    else:
        print(f"â„¹ï¸ è§†é¢‘ä¿å­˜æ¡ä»¶æœªæ»¡è¶³ï¼ˆéœ€åŒæ—¶å¯ç”¨å¯è§†åŒ–+rgb_arrayæ¨¡å¼+save_videoå‚æ•°ï¼‰")
    
    # 4. å¤šè½®ä»¿çœŸï¼ˆæ ‡å‡†Gymæ¥å£ï¼Œå®Œå…¨åŒ¹é…TwoCarrierEnvï¼‰
    episode_rewards = []
    episode_lengths = []
    episode_hinge_forces = []  # è®°å½•æ¯è½®é“°æ¥åŠ›
    
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆè¯„æµ‹æ¨¡å¼ï¼‰
        for episode_idx in range(args.num_episodes):
            print(f"\n--- Episode {episode_idx+1} ---")
            
            # é‡ç½®ç¯å¢ƒï¼ˆç²¾å‡†åŒ¹é…resetå‚æ•°ï¼‰
            obs, info = sim_env.reset(
                seed=42 + episode_idx,  # å›ºå®šç§å­ï¼Œä¿è¯å¯å¤ç°
                options={"clear_frames": True},
                clear_frames=True
            )
            # è½¬æ¢obsä¸ºTensorï¼ˆæ¨¡å‹è¾“å…¥éœ€è¦ï¼‰
            obs = torch.tensor(obs, dtype=torch.float32, device=final_device)
            
            # æ¸…ç©ºå¸§ç¼“å­˜ï¼ˆä»…å½“å¯ç”¨å¯è§†åŒ–æ—¶ï¼‰
            if args.enable_visualization:
                sim_env.clear_render_frames()
            
            ep_reward = 0.0
            ep_length = 0
            ep_hinge_forces = []  # è®°å½•æœ¬è½®æ¯æ­¥é“°æ¥åŠ›
            terminated = False
            truncated = False
            
            while not (terminated or truncated):
                # a. å‡†å¤‡æ¨¡å‹è¾“å…¥ï¼ˆæ·»åŠ batchç»´åº¦: [12] â†’ [1, 12]ï¼‰
                obs_batch = obs.unsqueeze(0)
                
                # b. æ¨¡å‹é¢„æµ‹åŠ¨ä½œï¼ˆ4ç»´ï¼Œå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
                model_output = actor(obs_batch)
                action_tensor = extract_action_from_model_output(model_output, final_device)
                # print(f" Step{ep_length :4d} | Action (normalized): {action_tensor.squeeze(0).cpu().numpy().round(3)}")
                # ç§»é™¤batchç»´åº¦ + è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆç¯å¢ƒæ¥å—numpyï¼‰
                action_np = action_tensor.squeeze(0).cpu().numpy()
                action_np[0] = np.clip(
                    action_np[0], 
                    -0.2, 0.2  # é™åˆ¶u2åŠ¨ä½œèŒƒå›´
                )
                action_np[1] = np.clip(
                    action_np[1], 
                    -0.2, 0.2  # é™åˆ¶u2åŠ¨ä½œèŒƒå›´
                )
                # action_np = np.array([-1, -1, 1, 0])
                # print(f" Predicted action (normalized): {action_np.round(3)}")
                # c. ç¯å¢ƒstepï¼ˆæ ‡å‡†Gymæ¥å£ï¼Œç¯å¢ƒè‡ªåŠ¨åå½’ä¸€åŒ–åŠ¨ä½œï¼‰
                obs, reward, terminated, truncated, info = sim_env.step(action_np)

                # print(f" Step{ep_length :4d} | u1_original: {info['u1'].round(3)}")
                # print(f" Step{ep_length :4d} | u2_original: {info['u2_original'].round(3)}")
                # print(f" Step{ep_length :4d} | u2_normalized: {info['u2_normalized'].round(3)}")
                # print(f" Step{ep_length :4d} | x: {info['x'].round(3)}")

                # d. è½¬æ¢æ–°obsä¸ºTensorï¼ˆä¸‹ä¸€è½®æ¨¡å‹è¾“å…¥ï¼‰
                obs = torch.tensor(obs, dtype=torch.float32, device=final_device)
                
                # e. ç´¯è®¡æ•°æ®
                ep_reward += reward
                ep_length += 1
                ep_hinge_forces.append(info['Fh2'])  # è®°å½•é“°æ¥åŠ›
                
                # f. æ‰“å°è¿›åº¦ï¼ˆæ¯100æ­¥ï¼‰
                if ep_length % 100 == 0:
                    fh2_mag = np.hypot(info['Fh2'][0], info['Fh2'][1])  # é“°æ¥åŠ›å¤§å°
                    pos_error = info.get('pos_error', 0.0)
                    print(f"  Step {ep_length} | å½“å‰å¥–åŠ±: {ep_reward:.2f} | é“°æ¥åŠ›å¤§å°: {fh2_mag:.2f} | ä½ç½®è¯¯å·®: {pos_error:.2f}")
            
            # 5. è®°å½•æœ¬è½®ç»“æœ
            episode_rewards.append(ep_reward)
            episode_lengths.append(ep_length)
            episode_hinge_forces.append(ep_hinge_forces)
            
            # è®¡ç®—æœ¬è½®é“°æ¥åŠ›ç»Ÿè®¡
            ep_hinge_array = np.array(ep_hinge_forces)
            ep_hinge_mag = np.hypot(ep_hinge_array[:, 0], ep_hinge_array[:, 1])
            avg_hinge_force = np.mean(ep_hinge_mag)
            max_hinge_force = np.max(ep_hinge_mag)
            
            print(f"  Episode {episode_idx+1:2d} ç»Ÿè®¡:")
            print(f"    æ€»å¥–åŠ±: {ep_reward:.2f} | æ€»æ­¥æ•°: {ep_length}")
            print(f"    å¹³å‡é“°æ¥åŠ›: {avg_hinge_force:.2f} | æœ€å¤§é“°æ¥åŠ›: {max_hinge_force:.2f}")
            
            # 6. ä¿å­˜æœ¬è½®è§†é¢‘ï¼ˆå®Œå…¨åŒ¹é…ç¯å¢ƒçš„save_eval_videoæ–¹æ³•ï¼‰
            if args.save_video and args.enable_visualization and args.render_mode == "rgb_array":
                try:
                    video_path = sim_env.save_eval_video(
                        eval_round=f"offline_ep{episode_idx+1}",
                        video_save_dir=video_save_dir
                    )
                    if video_path:
                        print(f"    âœ… è§†é¢‘å·²ä¿å­˜: {video_path}")
                except Exception as e:
                    print(f"    âš ï¸ è§†é¢‘ä¿å­˜å¤±è´¥: {e}")
            
            # æ ‡è®°ä»¿çœŸç»“æŸï¼ˆé¿å…resetæ—¶æ¸…ç©ºå¸§ï¼‰
            sim_env.mark_sim_finished()
    
    # 5. æ•´ä½“ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š ä»¿çœŸç»“æœæ±‡æ€»ï¼ˆ{args.num_episodes}è½®ï¼‰:")
    print(f"  å¹³å‡å¥–åŠ±: {np.mean(episode_rewards):.2f} Â± {np.std(episode_rewards):.2f}")
    print(f"  å¹³å‡æ­¥æ•°: {np.mean(episode_lengths):.2f} Â± {np.std(episode_lengths):.2f}")
    
    # é“°æ¥åŠ›ç»Ÿè®¡
    all_hinge_forces = []
    for ep_hf in episode_hinge_forces:
        ep_hf_array = np.array(ep_hf)
        all_hinge_forces.extend(np.hypot(ep_hf_array[:, 0], ep_hf_array[:, 1]))
    if all_hinge_forces:
        print(f"  å¹³å‡é“°æ¥åŠ›: {np.mean(all_hinge_forces):.2f} Â± {np.std(all_hinge_forces):.2f}")
        print(f"  æœ€å¤§é“°æ¥åŠ›: {np.max(all_hinge_forces):.2f}")
    
    print(f"  æœ€å¤§å¥–åŠ±è½®æ¬¡: ç¬¬{np.argmax(episode_rewards)+1}è½® ({np.max(episode_rewards):.2f})")
    print(f"  æœ€å°å¥–åŠ±è½®æ¬¡: ç¬¬{np.argmin(episode_rewards)+1}è½® ({np.min(episode_rewards):.2f})")
    
    # 6. å…³é—­ç¯å¢ƒï¼ˆè§¦å‘è§†é¢‘ç”Ÿæˆï¼‰
    sim_env.close()
    
    return {
        "episode_rewards": episode_rewards,
        "episode_lengths": episode_lengths,
        "episode_hinge_forces": episode_hinge_forces,
        "avg_reward": np.mean(episode_rewards),
        "std_reward": np.std(episode_rewards),
        "avg_hinge_force": np.mean(all_hinge_forces) if all_hinge_forces else 0.0
    }

# ===================== ä¸»å‡½æ•° =====================
def main():
    args = parse_args()
    
    CKPT_PATH="E:\rl\occt\outputs\2026-01-06\19-06-31\checkpoints_occt\checkpoint_1024000_frames.pt"
    DEVICE="cpu"
    # åŠ è½½Checkpoint
    actor, cfg, vecnorm_state = load_checkpoint(args.ckpt_path, args.device)
    
    # è¿è¡Œä»¿çœŸ
    sim_results = run_offline_simulation(actor, cfg, vecnorm_state, args)
    
    print(f"\nğŸ‰ ç¦»çº¿ä»¿çœŸå®Œæˆ!")
    print(f"  ç»“æœå·²ä¿å­˜ï¼Œå¹³å‡å¥–åŠ±: {sim_results['avg_reward']:.2f}")

if __name__ == "__main__":
    main()